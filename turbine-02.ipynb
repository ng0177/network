{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ng0177/network/blob/main/nonlinear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhB3iZZsWAWe"
   },
   "source": [
    "# Non linear regression / curve fitting\n",
    "\n",
    "You'll find more information and detailed explainations on [my blog](https://lucidar.me/en/neural-networks/curve-fitting-nonlinear-regression/).\n",
    "\n",
    "[Video of the expected result](https://youtu.be/7z86Lxzf_2o)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2pqhyoFbW4eA"
   },
   "source": [
    "## Check/install TensorFlow version\n",
    "**Must be version 2.1.0**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UuSy9cgA60Sy",
    "outputId": "6a930e5f-3251-404e-fb82-6f356f41c2a4"
   },
   "outputs": [],
   "source": [
    "# Switch the TensorFlow version 2.1\n",
    "#!pip install tensorflow==2.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qASyOjUDx1Lq"
   },
   "source": [
    "## Import libraries and create noisy data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rz1Q7i9xx1Lt",
    "outputId": "9f151272-62c9-4459-9444-89d8f99ca111"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.9.1\n",
      "Data created successfully\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "#from google.colab import files\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "print ('TensorFlow version: ' + tf.__version__)\n",
    "\n",
    "# Create noisy data\n",
    "#x_data = np.linspace(-10, 10, num=1000)\n",
    "#y_data = 0.1 * x_data * np.cos(x_data) + 0.1 * np.random.normal(size=1000)\n",
    "print('Data created successfully')\n",
    "x_data = np.array([[ 1.27305],[ 1.30392],[ 1.34063],[ 1.38482],[ 1.43878],[ 1.50577],[ 1.59061],[ 1.70066],[ 1.84776],[ 2.05185],[ 2.34924],[ 2.81181],[ 3.60117],[ 5.14998]])\n",
    "y_data = np.array([[ 1.34714],[ 1.41808],[ 1.47987],[ 1.55098],[ 1.62026],[ 1.69219],[ 1.76749],[ 1.83998],[ 1.91347],[ 1.98128],[ 2.04018],[ 2.08743],[ 2.12260],[ 2.14005]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGNdmgOKAg_D"
   },
   "source": [
    "## Display curve to fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "zYrNbXAsAf9N",
    "outputId": "e367e7da-7b10-46bd-b58b-1c6ec6616fab"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the dataset\n",
    "plt.scatter(x_data[::1], y_data[::1], s=2)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.savefig('dataset.png',dpi=300)\n",
    "#files.download('dataset.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5f_ikNz8x1Lz"
   },
   "source": [
    "# Create the model\n",
    "Create the model with two 64 units hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "sMvpBFj5x1L0",
    "outputId": "90bd03ca-c48b-4f5a-d322-bcb6bd76a03d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               256       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,137\n",
      "Trainable params: 11,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-19 18:41:00.400924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-19 18:41:00.419122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-19 18:41:00.419245: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-19 18:41:00.419747: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-19 18:41:00.420400: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-19 18:41:00.420487: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-19 18:41:00.420559: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-19 18:41:00.652594: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-19 18:41:00.652720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-19 18:41:00.652800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-19 18:41:00.652860: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0\n",
      "2022-08-19 18:41:00.652931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3246 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2022-08-19 18:41:00.653094: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# Create the model \n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=128,input_shape=(1,), activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1,))\n",
    "model.compile(optimizer='adam',loss = 'mae')\n",
    "\n",
    "# Display the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sxr1qxVex1L4"
   },
   "source": [
    "## Training over 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "M3XBJMj4x1L5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 1.7830\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7163\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6540\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5980\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5505\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5056\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4587\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4106\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3665\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3203\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2684\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2152\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1561\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0932\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0267\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9547\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8772\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8075\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7480\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6852\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6187\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5621\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5134\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4640\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4284\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3976\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3793\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3706\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3864\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4180\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4381\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4233\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3965\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3741\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3620\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3562\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3592\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3612\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3624\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3627\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3647\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3646\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3618\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3565\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3503\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3453\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3402\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3347\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3306\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3279\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3262\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3272\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3260\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3228\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3179\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3142\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3123\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3102\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3082\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3061\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3040\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3019\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2996\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2973\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2948\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2923\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2898\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2873\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2847\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2821\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2794\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2767\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2739\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2717\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2696\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2672\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2646\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2618\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2588\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2559\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2551\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2525\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2492\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2471\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2453\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2431\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2407\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2382\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2354\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2331\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2309\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2284\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2266\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2248\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2230\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2212\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2194\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2176\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2158\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2139\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2120\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2097\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2074\n",
      "Epoch 104/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2055\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2035\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2014\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1995\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1975\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1953\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1930\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1908\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1886\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1863\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1839\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1815\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1790\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1764\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1738\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1712\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1693\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1660\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1641\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1626\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1612\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1592\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1564\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1547\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1534\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1515\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1498\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1484\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1470\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1455\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1439\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1423\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1414\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1406\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1392\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1383\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1373\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1361\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1348\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1335\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1321\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1306\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1324\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1305\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1291\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1295\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1302\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1284\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1258\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1294\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1301\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1266\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1250\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1269\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1255\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1216\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1229\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1208\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1224\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1218\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1192\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1183\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1194\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1174\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1217\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1220\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1185\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1194\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1212\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1193\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1150\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1167\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1149\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1151\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1141\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1151\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1144\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1134\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1131\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1124\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1131\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1110\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1132\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1126\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1096\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1099\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1093\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1081\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1105\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1092\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1084\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1083\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1058\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1055\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1047\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1056\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1055\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1034\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1069\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1067\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1028\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1047\n",
      "Epoch 206/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1061\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1032\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1005\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1033\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1039\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1004\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0997\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1024\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1011\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0972\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0986\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1000\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0955\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0976\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0972\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0945\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0935\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0937\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0916\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0916\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0908\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0893\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0958\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0926\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0911\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0912\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0911\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0890\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0960\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0860\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0945\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0918\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0866\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0932\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0839\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0958\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0899\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0884\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0891\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0827\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0878\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0829\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0859\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0852\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0813\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0880\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0803\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0829\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0847\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0828\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0779\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0906\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0826\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0884\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0914\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0763\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0969\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0976\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0753\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0962\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1043\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0811\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0936\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1072\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0971\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0765\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0872\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0817\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0760\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0798\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0745\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0758\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0761\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0738\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0730\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0719\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0716\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0725\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0777\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0716\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0705\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0755\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0724\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0683\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0743\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0677\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0677\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0824\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0784\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0734\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0773\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0679\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0718\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0675\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff1e1f67df0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "model.fit(x_data, y_data,epochs=300, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gLEzVkjex1L9"
   },
   "source": [
    "# Predict and display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "IcKpdLe9x1L-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the output \n",
    "y_predicted = model.predict(x_data)\n",
    "\n",
    "# Display the result\n",
    "plt.scatter(x_data[::1], y_data[::1], s=1)\n",
    "plt.plot(x_data, y_predicted, 'r', linewidth=4)\n",
    "plt.grid()\n",
    "#plt.show()\n",
    "plt.savefig('training.png', dpi=300)\n",
    "#files.download(\"training.png\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OEEhzK4YHOdC"
   },
   "source": [
    "## Create image sequence for the video\n",
    "\n",
    "Run this section to generate a sequence of images for the [video](https://www.youtube.com/watch?v=7z86Lxzf_2o).\n",
    "\n",
    "To get the video from the beginning, you have to reset the model weight. Re-creating the model should reseting the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "13RiCs72HMH6"
   },
   "outputs": [],
   "source": [
    "#for x in range(100):\n",
    "#  # One epoch\n",
    "#  model.fit( x_data, y_data, epochs=1, verbose=1)\n",
    "#\n",
    "#  # Compute the output \n",
    "#  y_predicted = model.predict(x_data)\n",
    "#\n",
    "#  # Display the result\n",
    "#  plt.scatter(x_data[::1], y_data[::1], s=2)\n",
    "#  plt.plot(x_data, y_predicted, 'r', linewidth=4)\n",
    "#  plt.grid()\n",
    "#  plt.ylim(top=1.2)  # adjust the top leaving bottom unchanged\n",
    "#  plt.ylim(bottom=-1.2)  \n",
    "#  #plt.show()\n",
    "#  plt.savefig('training-' + str(x) +'-epochs.png',dpi=300)\n",
    "#  #files.download('training-' + str(x) +'-epochs.png') \n",
    "#  plt.clf()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "nonlinear-regression.ipynb",
   "provenance": []
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
